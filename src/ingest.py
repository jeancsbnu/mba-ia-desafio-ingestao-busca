import os
from pathlib import Path
from dotenv import load_dotenv
import httpx
from langchain_google_genai import GoogleGenerativeAIEmbeddings
from langchain_openai import OpenAIEmbeddings
from langchain_community.document_loaders import PyPDFLoader
from langchain_postgres import PGVector
from langchain_text_splitters import RecursiveCharacterTextSplitter


load_dotenv()

def get_embeddings():
    provider = os.getenv("AI_PROVIDER", "openai").lower()
    http_client = httpx.Client(verify=False)
    if provider == "openai":
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            raise ValueError("OPENAI_API_KEY n√£o est√° definido.")
        return OpenAIEmbeddings(
            openai_api_key=api_key,
            model="text-embedding-3-small",
            http_client=http_client
        )
        
    elif provider == 'gemini':
        api_key = os.getenv("GOOGLE_API_KEY")
        if not api_key:
            raise ValueError("GOOGLE_API_KEY n√£o est√° definido.")
        return GoogleGenerativeAIEmbeddings(
            google_api_key=api_key,
            model="models/embedding-001"
        )
    else:
        raise ValueError(f"Provider '{provider}' n√£o suportado. Use 'openai' ou 'gemini'")

def ingest_pdf():
    print("üîÑ Iniciando processo de ingest√£o...")

    documents = import_pdf_data()

    chunks = generate_chunks(documents)
    
    embeddings = setup_embeddings()

    database_url = retrieve_database_url()
    collection_name = os.getenv("PG_VECTOR_COLLECTION_NAME")
    
    print(f"üíæ Armazenando {len(chunks)} chunks no banco de dados...")
    print("‚è≥ Este processo pode levar alguns minutos...")

    vector_store = PGVector.from_documents(
        documents=chunks,
        embedding=embeddings,
        collection_name=collection_name,
        connection=database_url,
        use_jsonb=True
    )
    print(f"‚úÖ Ingest√£o conclu√≠da com sucesso!")
    print(f"üìä Total de chunks armazenados: {len(chunks)}")
    print(f"üì¶ Cole√ß√£o: {collection_name}")

    return vector_store

def import_pdf_data():
    current_dir = Path(__file__).parent.parent
    pdf_path = current_dir / "document.pdf"
    
    if not pdf_path.exists():
        raise FileNotFoundError(f"PDF n√£o encontrado: {pdf_path}")

    print(f"üìÑ Carregando PDF: {pdf_path}")
    loader = PyPDFLoader(pdf_path)
    documents = loader.load()
    print(f"‚úÖ PDF carregado: {len(documents)} p√°gina(s)")
    return documents

def setup_embeddings():
    print("üîß Configurando modelo de embeddings...")
    embeddings = get_embeddings()
    provider = os.getenv("AI_PROVIDER", "openai")
    print(f"‚úÖ Usando provider: {provider}")
    return embeddings

def generate_chunks(documents):
    print("‚úÇÔ∏è  Dividindo documento em chunks...")
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=1000,
        chunk_overlap=150,
        length_function=len,
    )
    chunks = text_splitter.split_documents(documents)
    print(f"‚úÖ Documento dividido em {len(chunks)} chunks")
    return chunks

def retrieve_database_url():
    database_url = os.getenv("DATABASE_URL")
    if not database_url:
        raise ValueError("DATABASE_URL n√£o encontrada no arquivo .env")
    return database_url


if __name__ == "__main__":
    try:
        ingest_pdf()
    except Exception as e:
        print(f"‚ùå Erro durante a ingest√£o: {str(e)}")
        raise