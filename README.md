# ğŸ” Sistema de IngestÃ£o e Busca SemÃ¢ntica com LangChain e PostgreSQL

Sistema completo de processamento de PDFs com busca semÃ¢ntica utilizando LangChain, PostgreSQL + pgVector e modelos de IA (OpenAI ou Google Gemini).

## ğŸ“‹ Funcionalidades

- **IngestÃ£o de PDF**: Processa documentos PDF, divide em chunks e armazena embeddings no banco vetorial
- **Busca SemÃ¢ntica**: Realiza buscas por similaridade usando vetores
- **Chat Interativo**: Interface CLI para fazer perguntas sobre o conteÃºdo do PDF
- **Suporte Multi-Provider**: CompatÃ­vel com OpenAI e Google Gemini

## ğŸ› ï¸ Tecnologias

- **Python 3.8+**
- **LangChain**: Framework para aplicaÃ§Ãµes com LLMs
- **PostgreSQL + pgVector**: Banco de dados vetorial
- **Docker & Docker Compose**: ContainerizaÃ§Ã£o do banco de dados
- **OpenAI API** ou **Google Gemini API**: Modelos de embeddings e LLM

## ğŸ“¦ Estrutura do Projeto

```
â”œâ”€â”€ docker-compose.yml      # ConfiguraÃ§Ã£o do PostgreSQL com pgVector
â”œâ”€â”€ requirements.txt        # DependÃªncias Python
â”œâ”€â”€ .env.example           # Template das variÃ¡veis de ambiente
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ ingest.py         # Script de ingestÃ£o do PDF
â”‚   â”œâ”€â”€ search.py         # Script de busca semÃ¢ntica
â”‚   â””â”€â”€ chat.py           # Interface CLI interativa
â”œâ”€â”€ document.pdf          # PDF para ingestÃ£o (adicione seu arquivo)
â””â”€â”€ README.md             # Este arquivo
```

## ğŸš€ InstalaÃ§Ã£o e ConfiguraÃ§Ã£o

### 1. PrÃ©-requisitos

- Python 3.8 ou superior
- Docker e Docker Compose instalados
- Conta OpenAI ou Google Cloud (para APIs)

### 2. Criar e Ativar Ambiente Virtual

```bash
# Criar ambiente virtual
python3 -m venv venv

# Ativar no Linux/Mac
source venv/bin/activate

# Ativar no Windows
venv\Scripts\activate
```

### 3. Instalar DependÃªncias

```bash
pip install -r requirements.txt
```

### 4. Configurar VariÃ¡veis de Ambiente

Copie o arquivo `.env.example` para `.env`:

```bash
cp .env.example .env
```

Edite o arquivo `.env` e configure suas credenciais:

**Para OpenAI:**
```env
AI_PROVIDER=openai
OPENAI_API_KEY=sk-your-api-key-here
DATABASE_URL=postgresql+psycopg://postgres:postgres@localhost:5432/rag
```

**Para Google Gemini:**
```env
AI_PROVIDER=gemini
GOOGLE_API_KEY=your-google-api-key-here
DATABASE_URL=postgresql+psycopg://postgres:postgres@localhost:5432/rag
```

### 5. Subir o Banco de Dados

```bash
docker compose up -d
```

Aguarde o banco inicializar (cerca de 10 segundos). Verifique o status:

```bash
docker compose ps
```

## ğŸ“– Como Usar

### Passo 1: Adicionar o PDF

Coloque seu arquivo PDF na raiz do projeto com o nome `document.pdf`, ou edite o caminho no script `src/ingest.py`.

### Passo 2: Executar IngestÃ£o

Execute o script de ingestÃ£o para processar o PDF e armazenar no banco:

```bash
python src/ingest.py
```

**SaÃ­da esperada:**
```
ğŸ”„ Iniciando processo de ingestÃ£o...
ğŸ“„ Carregando PDF: document.pdf
âœ… PDF carregado: 10 pÃ¡gina(s)
âœ‚ï¸  Dividindo documento em chunks...
âœ… Documento dividido em 87 chunks
ğŸ”§ Configurando modelo de embeddings...
âœ… Usando provider: openai
ğŸ’¾ Armazenando 87 chunks no banco de dados...
â³ Este processo pode levar alguns minutos...
âœ… IngestÃ£o concluÃ­da com sucesso!
ğŸ“Š Total de chunks armazenados: 87
ğŸ“¦ ColeÃ§Ã£o: pdf_documents
```

### Passo 3: Rodar o Chat Interativo

Inicie o chat para fazer perguntas:

```bash
python src/chat.py
```

**Exemplo de interaÃ§Ã£o:**

```
============================================================
ğŸ¤– Sistema de Busca SemÃ¢ntica em PDF
============================================================
ğŸ“¡ Provider: OPENAI
ğŸ’¡ Digite 'sair' ou 'exit' para encerrar
============================================================

FaÃ§a sua pergunta:

PERGUNTA: Qual o faturamento da Empresa SuperTechIABrazil?
ğŸ” Buscando informaÃ§Ãµes...
RESPOSTA: O faturamento foi de 10 milhÃµes de reais.

------------------------------------------------------------

FaÃ§a sua pergunta:

PERGUNTA: Quantos clientes temos em 2024?
ğŸ” Buscando informaÃ§Ãµes...
RESPOSTA: NÃ£o tenho informaÃ§Ãµes necessÃ¡rias para responder sua pergunta.

------------------------------------------------------------

PERGUNTA: sair
ğŸ‘‹ Encerrando o chat. AtÃ© logo!
```

## ğŸ”§ ConfiguraÃ§Ãµes TÃ©cnicas

### Modelos Utilizados

**OpenAI:**
- Embeddings: `text-embedding-3-small`
- LLM: `gpt-4o-mini` (ajustÃ¡vel no cÃ³digo)

**Google Gemini:**
- Embeddings: `models/embedding-001`
- LLM: `gemini-2.0-flash-exp` (ajustÃ¡vel no cÃ³digo)

### ParÃ¢metros de Chunking

- **Chunk Size**: 1000 caracteres
- **Overlap**: 150 caracteres
- **Resultados por busca (k)**: 10

### Banco de Dados

- **Host**: localhost
- **Porta**: 5432
- **UsuÃ¡rio**: postgres
- **Senha**: postgres
- **Database**: vectordb

## ğŸ› Troubleshooting

### Erro: "OPENAI_API_KEY nÃ£o encontrada"
Verifique se o arquivo `.env` existe e contÃ©m a chave de API vÃ¡lida.

### Erro: "Arquivo nÃ£o encontrado: document.pdf"
Certifique-se de que o arquivo PDF estÃ¡ na raiz do projeto ou ajuste o caminho em `src/ingest.py`.

### Erro de conexÃ£o com o banco
Verifique se o Docker estÃ¡ rodando e se o container PostgreSQL estÃ¡ ativo:
```bash
docker compose ps
docker compose logs postgres
```

### Reiniciar o banco de dados
```bash
docker compose down
docker compose up -d
```

## ğŸ§¹ Limpeza

Para parar e remover o banco de dados:

```bash
# Parar os containers
docker compose down

# Remover volumes (apaga os dados)
docker compose down -v
```

## ğŸ“ Notas Importantes

- O sistema responde apenas com base no conteÃºdo do PDF processado
- Perguntas fora do contexto retornarÃ£o a mensagem padrÃ£o de "informaÃ§Ãµes nÃ£o disponÃ­veis"
- O processo de ingestÃ£o pode demorar dependendo do tamanho do PDF

## ğŸ¤ Suporte

Para problemas ou dÃºvidas:
1. Verifique se todas as dependÃªncias foram instaladas
2. Confirme que as variÃ¡veis de ambiente estÃ£o configuradas
3. Verifique os logs do Docker: `docker compose logs`

## ğŸ“„ LicenÃ§a

Este projeto Ã© fornecido como exemplo educacional.