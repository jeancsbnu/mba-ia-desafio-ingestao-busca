# MBA | Engenharia de Software com IA - Chat Sem√¢ntico com LangChain e PGVector

> üá¨üáß **English version available:** [README_EN.md](README_EN.md)

Este projeto √© uma aplica√ß√£o de chat com busca sem√¢ntica (RAG - Retrieval-Augmented Generation) desenvolvida como parte do MBA em Engenharia de Software com IA. A aplica√ß√£o permite que o usu√°rio fa√ßa perguntas em linguagem natural sobre o conte√∫do de um documento PDF, e o sistema utiliza um modelo de linguagem (LLM) para fornecer respostas precisas com base exclusivamente no contexto encontrado no documento.

## Vis√£o Geral

A aplica√ß√£o implementa um fluxo de RAG completo:
1.  **Ingest√£o de Dados:** Um documento PDF (`document.pdf`) √© lido, dividido em trechos (chunks) e processado.
2.  **Gera√ß√£o de Embeddings:** Para cada trecho, um embedding vetorial √© gerado usando modelos de embedding (Google Gemini ou OpenAI).
3.  **Armazenamento:** Os trechos de texto e seus embeddings correspondentes s√£o armazenados em um banco de dados PostgreSQL com a extens√£o `pgvector`.
4.  **Busca Sem√¢ntica:** Quando o usu√°rio faz uma pergunta, ela √© convertida em um embedding e usada para buscar os trechos mais relevantes (semanticamente similares) no banco de dados.
5.  **Gera√ß√£o de Resposta:** Os trechos recuperados s√£o injetados como contexto em um prompt, que √© ent√£o enviado a um LLM (Google Gemini ou OpenAI) para gerar uma resposta coesa e baseada nos fatos.

## Arquitetura e Tecnologias

-   **Linguagem:** Python
-   **Orquestrador de LLM:** LangChain
-   **Modelos de Linguagem (LLM):** Google Gemini (via `langchain-google-genai`) ou OpenAI (via `langchain-openai`)
-   **Modelos de Embedding:** Google Embedding API ou OpenAI Embeddings
-   **Banco de Dados Vetorial:** PostgreSQL com a extens√£o `pgvector`
-   **Containeriza√ß√£o:** Docker e Docker Compose
-   **Interface:** Aplica√ß√£o de linha de comando (CLI)

## Pr√©-requisitos

Antes de come√ßar, certifique-se de que voc√™ tem os seguintes softwares instalados:
-   [Docker](https://www.docker.com/get-started)
-   [Docker Compose](https://docs.docker.com/compose/install/) (geralmente inclu√≠do na instala√ß√£o do Docker)
-   [Python 3.10+](https://www.python.org/downloads/)

## Configura√ß√£o

1.  **Clone o Reposit√≥rio**
    ```bash
    git clone https://github.com/juniordsi/mba-ai-langchain-postgres-semantic-search.git
    cd mba-ai-langchain-postgres-semantic-search
    ```

2.  **Configure as Vari√°veis de Ambiente**
    
    A aplica√ß√£o suporta tanto modelos do Google Gemini quanto da OpenAI. Use o arquivo `.env.example` como base para criar seu arquivo `.env`:

    ```bash
    cp .env.example .env
    ```

    ### Op√ß√£o 1: Usando Google Gemini (Recomendado)
    
    Edite o arquivo `.env` e configure as seguintes vari√°veis:

    ```env
    # Obtenha sua chave em https://aistudio.google.com/app/apikey
    GOOGLE_API_KEY="SUA_CHAVE_DE_API_DO_GOOGLE"
    GOOGLE_MODEL="gemini-1.5-flash"
    GOOGLE_EMBEDDING_MODEL="models/embedding-001"
    
    # Configura√ß√µes do banco de dados
    DATABASE_URL="postgresql://postgres:postgres@localhost:5432/rag"
    PG_VECTOR_COLLECTION_NAME="documentos"
    PDF_PATH="document.pdf"
    ```

    ### Op√ß√£o 2: Usando OpenAI
    
    Alternativamente, para usar modelos da OpenAI, configure:

    ```env
    # Obtenha sua chave em https://platform.openai.com/api-keys
    OPENAI_API_KEY="SUA_CHAVE_DE_API_DA_OPENAI"
    OPENAI_MODEL="gpt-3.5-turbo"
    OPENAI_EMBEDDING_MODEL="text-embedding-3-small"
    
    # Configura√ß√µes do banco de dados
    DATABASE_URL="postgresql://postgres:postgres@localhost:5432/rag"
    PG_VECTOR_COLLECTION_NAME="documentos"
    PDF_PATH="document.pdf"
    ```

    **Importante:** Voc√™ deve configurar **apenas um** dos provedores (Google OU OpenAI), n√£o ambos.

## Execu√ß√£o da Aplica√ß√£o

Para simplificar a inicializa√ß√£o, foi criado um script `start.py` que automatiza todo o processo.

**Para iniciar a aplica√ß√£o, execute o seguinte comando no seu terminal:**

```bash
python3 start.py chat
```

Este comando ir√° realizar as seguintes etapas automaticamente:
1.  **Iniciar o Docker:** Executa `docker compose up -d` para iniciar o banco de dados PostgreSQL em segundo plano.
2.  **Criar Ambiente Virtual:** Cria um ambiente virtual `venv` na raiz do projeto (se n√£o existir).
3.  **Instalar Depend√™ncias:** Instala todas as bibliotecas Python necess√°rias a partir do arquivo `requirements.txt`.
4.  **Ingerir os Dados:** Executa o script `src/ingest.py` para processar o `document.pdf` e popular o banco de dados.
5.  **Iniciar o Chat:** Executa o script `src/chat.py`, permitindo que voc√™ comece a interagir com a aplica√ß√£o.

Ap√≥s a inicializa√ß√£o, voc√™ poder√° fazer perguntas diretamente no terminal. Para encerrar, digite `sair`.